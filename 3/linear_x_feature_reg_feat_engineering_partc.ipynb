{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "id": "wWW6pnedjPlv"
   },
   "outputs": [],
   "source": [
    "#import stuff here\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "the_Cj9wTUtU",
    "outputId": "f9dfd8fe-fb47-4f95-aeaf-d4742082ab77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39644, 58)\n"
     ]
    }
   ],
   "source": [
    "#The file \"Stand_Data.csv\" generated from \"Standardization.ipynb\" is required\n",
    "file_dir = \"Stand_Data.csv\"\n",
    "data = np.loadtxt(file_dir, delimiter=\",\")\n",
    "print(np.shape(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-AqvdzahS1eW"
   },
   "source": [
    "# PART A:\n",
    "Start with a basic linear model (the features are only standardized and are used as they are\n",
    "without any transformations) regardless if you are doing the least-squares data fitting (Chapter\n",
    "13) or the least-squares classification (Chapter 14) task. Evaluate the initial model using cross-\n",
    "validation and report the RMS error. Make sure to save the model parameters for each fold of\n",
    "the cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VcoKBL-hTxCL",
    "outputId": "df4b35ec-325a-4fbf-bbab-13e792e023a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39644,)\n"
     ]
    }
   ],
   "source": [
    "#The file 'OnlineNewsPopularity.csv' from https://archive.ics.uci.edu/dataset/332/online+news+popularity is required\n",
    "file_dir2 = 'OnlineNewsPopularity.csv'\n",
    "columns = [60]\n",
    "target = np.loadtxt(file_dir2, delimiter = ',', skiprows=1, usecols = columns)\n",
    "print(np.shape(target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5cBlwwJv_Vhd"
   },
   "source": [
    "##Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A9JLnDzF8j5O",
    "outputId": "bae004bd-b93b-400a-d5f2-13bb5b4c7dfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39644, 59)\n"
     ]
    }
   ],
   "source": [
    "#Add a column of 1's to the right side of A\n",
    "A = data\n",
    "A = np.vstack((A.T, np.ones(39644))).T\n",
    "print(np.shape(A))\n",
    "\n",
    "#solve least squares problem\n",
    "params = np.linalg.lstsq(A, target, rcond=None)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ntQ3k7Z2_pae"
   },
   "source": [
    "##Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6wL905kuIaf5"
   },
   "source": [
    "###Calculate RMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "id": "IF8h1hmPIYUV"
   },
   "outputs": [],
   "source": [
    "def RME(x_test, y_test, params):\n",
    "  preds = []\n",
    "  data_size = x_test.shape[0]\n",
    "  for i in range(data_size):\n",
    "    pred = np.dot(x_test[i], params[:58]) + params[58]\n",
    "    preds.append(pred)\n",
    "  return math.sqrt((np.sum(np.square(np.subtract(y_test, preds))))/data_size)\n",
    "\n",
    "#print(RME(data,target,params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4aXFuELsajmx"
   },
   "source": [
    "###Cross Validation Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TebhSeCz_xsy",
    "outputId": "36e1fdab-a9c3-4cb4-a066-cd32f52730e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 RMS Error: 12953.320171324256\n",
      "Fold 2 RMS Error: 12239.76141359509\n",
      "Fold 3 RMS Error: 15904.998478589163\n",
      "Fold 4 RMS Error: 6448.062377989548\n",
      "Fold 5 RMS Error: 8065.5797471211845\n",
      "Cross Validated RMS Error: 11496.127994612103\n",
      "Normal Linear Regression RMS Error: 11491.736924948345\n"
     ]
    }
   ],
   "source": [
    "#Train on 5 folds, indexes: [0-7928, 7929-15857, 15858-23786, 23787-31715, 31716-39643]\n",
    "#fold 1\n",
    "x_train1 = A[7929:,:]\n",
    "x_test1 = data[:7979,:]\n",
    "y_train1 = target[7929:]\n",
    "y_test1 = target[:7979]\n",
    "params1 = np.linalg.lstsq(x_train1, y_train1, rcond=None)[0]\n",
    "print(f\"Fold 1 RMS Error: {RME(x_test1, y_test1, params1)}\")\n",
    "\n",
    "#fold 2\n",
    "x_train2 = np.vstack((A[:7929,:], A[15858:,:]))\n",
    "x_test2 = data[7929:15858,:]\n",
    "y_train2 = np.concatenate((target[:7929], target[15858:]))\n",
    "y_test2 = target[7929:15858]\n",
    "params2 = np.linalg.lstsq(x_train2, y_train2, rcond=None)[0]\n",
    "print(f\"Fold 2 RMS Error: {RME(x_test2, y_test2, params2)}\")\n",
    "\n",
    "#fold 3\n",
    "x_train3 = np.vstack((A[:15858,:], A[23787:,:]))\n",
    "x_test3 = data[15858:23787,:]\n",
    "y_train3 = np.concatenate((target[:15858], target[23787:]))\n",
    "y_test3 = target[15858:23787]\n",
    "params3 = np.linalg.lstsq(x_train3, y_train3, rcond=None)[0]\n",
    "print(f\"Fold 3 RMS Error: {RME(x_test3, y_test3, params3)}\")\n",
    "\n",
    "#fold 4\n",
    "x_train4 = np.vstack((A[:23787,:], A[31716:,:]))\n",
    "x_test4 = data[23787:31716,:]\n",
    "y_train4 = np.concatenate((target[:23787], target[31716:]))\n",
    "y_test4 = target[23787:31716]\n",
    "params4 = np.linalg.lstsq(x_train4, y_train4, rcond=None)[0]\n",
    "print(f\"Fold 4 RMS Error: {RME(x_test4, y_test4, params4)}\")\n",
    "\n",
    "#fold 5\n",
    "x_train5 = A[:31716,:]\n",
    "x_test5 = data[31716:,:]\n",
    "y_train5 = target[:31716]\n",
    "y_test5 = target[31716:]\n",
    "params5 = np.linalg.lstsq(x_train5, y_train5, rcond=None)[0]\n",
    "print(f\"Fold 5 RMS Error: {RME(x_test5, y_test5, params5)}\")\n",
    "\n",
    "#take the average parameter values of the five folds\n",
    "params_mean = np.zeros(59)\n",
    "for i in range(59):\n",
    "  params_mean[i] = (params1[i] + params2[i] + params3[i] + params4[i] + params5[i])/5\n",
    "print(f\"Cross Validated RMS Error: {RME(data, target, params_mean)}\")\n",
    "print(f\"Normal Linear Regression RMS Error: {RME(data,target,params)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-pUCmQrbAlB"
   },
   "source": [
    "#PART B:\n",
    "Perform feature engineering. Come up with more interesting feature mappings or basis functions\n",
    "for the linear least-squares data fitting or the linear least-squares classifier. For example, try out\n",
    "a stratified model (Chapter 13.3.2) using the results of the k-means clustering you did earlier.\n",
    "Choose the best model using cross-validation and report the RMS error. Make sure to save the\n",
    "model parameters for each fold of the cross-validation. If you are doing classification, report the\n",
    "confusion matrix for the best model you found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r8w0loMMdZiE"
   },
   "source": [
    "##Feature Engineering - Product Interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yp6KylFPf37u"
   },
   "source": [
    "###Determining 5 least significant factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z7uG6jIxbJHt",
    "outputId": "26366fc0-1b92-45c0-fe89-c6bde0d94f1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[31.          0.435544  ]\n",
      " [35.         10.36733501]\n",
      " [53.         17.43081268]\n",
      " [45.         22.70689072]\n",
      " [ 8.         23.18702348]]\n"
     ]
    }
   ],
   "source": [
    "#Sort the parameters by magnitude and retrieve the five features that contribute the least\n",
    "params_abs = abs(np.array(params[:58])) #take magnitude of feature parameters\n",
    "#attach the correlating index to teh parameter value\n",
    "indexes = list(range(0,58))\n",
    "stack = np.vstack((indexes, params_abs))\n",
    "#sort by parameter magnitude\n",
    "stack = stack.T\n",
    "sorted = stack[stack[:,1].argsort()]\n",
    "print(sorted[:5])\n",
    "worst_indexes = sorted[:5, 0] #list of indexes of least significant features\n",
    "worst_indexes = worst_indexes.astype(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oWf9_XKQmW8U"
   },
   "source": [
    "###Performing Feature Engineering\n",
    "We will be taking the 5 least significant features and multipling them with all other features to create a new feature to see if it is only important when considering another feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "6NQu9aRcmkTW",
    "outputId": "517e620f-5e7d-4573-a480-186182155bca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58, 39644)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nprint(np.shape(newdata))\\nprint(np.shape(B))\\nprint(\"done\")\\n'"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For each of the 5 least significant features, create a new feature by multiplying it with the 57 other features (creates a total of 285 new features)\n",
    "#B represents a modified A matrix\n",
    "B=data.T\n",
    "print(np.shape(B))\n",
    "i = 0 #i keeps track of which bad index we are on\n",
    "j = 0 #j represents all other features\n",
    "for i in range(5):\n",
    "  bad_index = worst_indexes[i]\n",
    "  for j in range(58):\n",
    "    feature_added = []\n",
    "    if i==j:\n",
    "      continue #irrelevent to consider a non significant feature with itself\n",
    "    else:\n",
    "      for k in range(39644): #k represents all the data points\n",
    "        feature_added.append(B[bad_index,k]*B[j,k])\n",
    "      B = np.vstack((B,feature_added))\n",
    "#newdata represents a modified data matrix\n",
    "newdata = B.T\n",
    "B = np.vstack((B,np.ones(39644)))\n",
    "B = B.T\n",
    "\"\"\"\n",
    "print(np.shape(newdata))\n",
    "print(np.shape(B))\n",
    "print(\"done\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kgNn3PUpZxFU"
   },
   "source": [
    "##Evaluate New Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "id": "URD4JFZRt82H"
   },
   "outputs": [],
   "source": [
    "def newRME(x_test, y_test, params):\n",
    "  preds = []\n",
    "  data_size = x_test.shape[0]\n",
    "  for i in range(data_size):\n",
    "    pred = np.dot(x_test[i], params[:343]) + params[343]\n",
    "    preds.append(pred)\n",
    "  return math.sqrt((np.sum(np.square(np.subtract(y_test, preds))))/data_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U7EixNX5qy7J",
    "outputId": "842e8769-234e-4c81-8037-7e5b096c87ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Fold 1 RMS Error: 15793.41339679203\n",
      "New Fold 2 RMS Error: 12375.805800802822\n",
      "New Fold 3 RMS Error: 15960.51636812314\n",
      "New Fold 4 RMS Error: 108183.84277710892\n",
      "New Fold 5 RMS Error: 8171.10214671604\n",
      "New Cross Validated RMS Error: 14987.738100057584\n",
      "New Linear Regression RMS Error: 11428.975821063592\n"
     ]
    }
   ],
   "source": [
    "newparams = np.linalg.lstsq(B, target, rcond=None)[0]\n",
    "\n",
    "\n",
    "#5 folds, indexes: [0-7928, 7929-15857, 15858-23786, 23787-31715, 31716-39643]\n",
    "#fold 1\n",
    "newx_train1 = B[7929:,:]\n",
    "newx_test1 = newdata[:7979,:]\n",
    "newy_train1 = target[7929:]\n",
    "newy_test1 = target[:7979]\n",
    "newparams1 = np.linalg.lstsq(newx_train1, newy_train1, rcond=None)[0]\n",
    "print(f\"New Fold 1 RMS Error: {newRME(newx_test1, newy_test1, newparams1)}\")\n",
    "\n",
    "\n",
    "#fold 2\n",
    "newx_train2 = np.vstack((B[:7929,:], B[15858:,:]))\n",
    "newx_test2 = newdata[7929:15858,:]\n",
    "newy_train2 = np.concatenate((target[:7929], target[15858:]))\n",
    "newy_test2 = target[7929:15858]\n",
    "newparams2 = np.linalg.lstsq(newx_train2, newy_train2, rcond=None)[0]\n",
    "print(f\"New Fold 2 RMS Error: {newRME(newx_test2, newy_test2, newparams2)}\")\n",
    "\n",
    "\n",
    "#fold 3\n",
    "newx_train3 = np.vstack((B[:15858,:], B[23787:,:]))\n",
    "newx_test3 = newdata[15858:23787,:]\n",
    "newy_train3 = np.concatenate((target[:15858], target[23787:]))\n",
    "newy_test3 = target[15858:23787]\n",
    "newparams3 = np.linalg.lstsq(newx_train3, newy_train3, rcond=None)[0]\n",
    "print(f\"New Fold 3 RMS Error: {newRME(newx_test3, newy_test3, newparams3)}\")\n",
    "\n",
    "\n",
    "#fold 4\n",
    "newx_train4 = np.vstack((B[:23787,:], B[31716:,:]))\n",
    "newx_test4 = newdata[23787:31716,:]\n",
    "newy_train4 = np.concatenate((target[:23787], target[31716:]))\n",
    "newy_test4 = target[23787:31716]\n",
    "newparams4 = np.linalg.lstsq(newx_train4, newy_train4, rcond=None)[0]\n",
    "print(f\"New Fold 4 RMS Error: {newRME(newx_test4, newy_test4, newparams4)}\")\n",
    "\n",
    "\n",
    "#fold 5\n",
    "newx_train5 = B[:31716,:]\n",
    "newx_test5 = newdata[31716:,:]\n",
    "newy_train5 = target[:31716]\n",
    "newy_test5 = target[31716:]\n",
    "newparams5 = np.linalg.lstsq(newx_train5, newy_train5, rcond=None)[0]\n",
    "print(f\"New Fold 5 RMS Error: {newRME(newx_test5, newy_test5, newparams5)}\")\n",
    "\n",
    "#take the average parameter value of the five folds\n",
    "newparams_mean = np.zeros(344)\n",
    "for i in range(344):\n",
    " newparams_mean[i] = (newparams1[i] + newparams2[i] + newparams3[i] + newparams4[i] + newparams5[i])/5\n",
    "print(f\"New Cross Validated RMS Error: {newRME(newdata, target, newparams_mean)}\")\n",
    "print(f\"New Linear Regression RMS Error: {newRME(newdata,target,newparams)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "13821.7649707273\n",
      "2386.922700781445\n"
     ]
    }
   ],
   "source": [
    "#regularizing linear model\n",
    "test_set = A[:19822]\n",
    "training_set = A[19822:]\n",
    "\n",
    "test_outcome = target[:19822]\n",
    "training_outcome = target[19822:]\n",
    "\n",
    "\n",
    "reg_param_values = [.001,1,10,20,100,200,300,400,600,1000,1200,1300,1500,1800,2000,2300,2600,3000,4000,5000,6000,7000,8000,9000,10000]\n",
    "fit_RMS = []\n",
    "param_norms = []\n",
    "\n",
    "\n",
    "\n",
    "for reg_param in reg_param_values:\n",
    "    dim = A.shape[1]\n",
    "    ident = np.identity(dim)\n",
    "    ident *= reg_param\n",
    "    ident[dim-1][dim-1] = 0\n",
    "    mat = np.vstack((training_set, ident))\n",
    "\n",
    "    \n",
    "\n",
    "    outcome = np.concatenate((training_outcome, np.zeros(dim)))\n",
    "    params = np.linalg.lstsq(mat, outcome, rcond=None)[0]\n",
    "    param_norm = np.linalg.norm(np.delete(params,dim-1)) \n",
    "    param_norms = np.append(param_norms, param_norm)\n",
    "\n",
    "\n",
    "    preds = []\n",
    "    for i in range(test_set.shape[0]):\n",
    "        pred = np.dot(test_set[i],params) \n",
    "        preds.append(pred)\n",
    "\n",
    "    dif = preds - test_outcome\n",
    "    norm_ = np.linalg.norm(dif)\n",
    "    fit_RMS.append(norm_/np.sqrt(dif.shape[0]))\n",
    "\n",
    "\n",
    "    \n",
    "lowest_RMS = np.argmin(fit_RMS)\n",
    "\n",
    "print(reg_param_values[lowest_RMS])\n",
    "print(fit_RMS[lowest_RMS])\n",
    "print(param_norms[lowest_RMS])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "13834.784062169654\n",
      "847.583449965849\n"
     ]
    }
   ],
   "source": [
    "#regularizing linear model\n",
    "test_set = B[:19822]\n",
    "training_set = B[19822:]\n",
    "\n",
    "test_outcome = target[:19822]\n",
    "training_outcome = target[19822:]\n",
    "\n",
    "\n",
    "reg_param_values = [.001,1,10,20,100,200,300,400,600,1000,1200,1300,1500,1800,2000,2300,2600,3000,4000,5000,6000,7000,8000,9000,10000]\n",
    "fit_RMS = []\n",
    "param_norm = []\n",
    "\n",
    "\n",
    "\n",
    "for reg_param in reg_param_values:\n",
    "    dim = B.shape[1]\n",
    "    ident = np.identity(dim)\n",
    "    ident *= reg_param\n",
    "    ident[dim-1][dim-1] = 0\n",
    "    mat = np.vstack((training_set, ident))\n",
    "\n",
    "    \n",
    "\n",
    "    outcome = np.concatenate((training_outcome, np.zeros(dim)))\n",
    "    params = np.linalg.lstsq(mat, outcome, rcond=None)[0]\n",
    "    param_norm = np.linalg.norm(np.delete(params,dim-1)) \n",
    "    param_norms = np.append(param_norms, param_norm)\n",
    "\n",
    "\n",
    "    preds = []\n",
    "    for i in range(test_set.shape[0]):\n",
    "        pred = np.dot(test_set[i],params) \n",
    "        preds.append(pred)\n",
    "\n",
    "    dif = preds - test_outcome\n",
    "    norm_ = np.linalg.norm(dif)\n",
    "    fit_RMS.append(norm_/np.sqrt(dif.shape[0]))\n",
    "    \n",
    "lowest_RMS = np.argmin(fit_RMS)\n",
    "\n",
    "print(reg_param_values[lowest_RMS])\n",
    "print(fit_RMS[lowest_RMS])\n",
    "print(param_norms[lowest_RMS])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39644, 59)\n",
      "20\n",
      "13828.735274427861\n",
      "2379.171643289668\n"
     ]
    }
   ],
   "source": [
    "#New Feature Engineering\n",
    "\n",
    "new_matrix = A\n",
    "\n",
    "print(A.shape)\n",
    "\n",
    "for i in range(A.shape[0]):\n",
    "    if A[i][7] > 0:\n",
    "        A[i][7] = 1\n",
    "    else:\n",
    "        A[i][7] = 0\n",
    "\n",
    "    if A[i][8] > 0:\n",
    "        A[i][8] = 1\n",
    "    else:\n",
    "        A[i][8] = 0\n",
    "\n",
    "    if A[i][26] > 0:\n",
    "        A[i][26] = np.log(A[i][26])\n",
    "\n",
    "    if A[i][27] > 0:\n",
    "        A[i][27] = np.log(A[i][27])\n",
    "\n",
    "    if A[i][28] > 0:\n",
    "        A[i][28] = np.log(A[i][28])\n",
    "    \n",
    "\n",
    "#regularizing linear model\n",
    "test_set = new_matrix[:19822]\n",
    "training_set = new_matrix[19822:]\n",
    "\n",
    "test_outcome = target[:19822]\n",
    "training_outcome = target[19822:]\n",
    "\n",
    "\n",
    "reg_param_values = [.001,1,10,20,100,200,300,400,600,1000,1200,1300,1500,1800,2000,2300,2600,3000,4000,5000,6000,7000,8000,9000,10000]\n",
    "fit_RMS = []\n",
    "param_norms = []\n",
    "\n",
    "\n",
    "\n",
    "for reg_param in reg_param_values:\n",
    "    dim = A.shape[1]\n",
    "    ident = np.identity(dim)\n",
    "    ident *= reg_param\n",
    "    ident[dim-1][dim-1] = 0\n",
    "    mat = np.vstack((training_set, ident))\n",
    "\n",
    "    \n",
    "\n",
    "    outcome = np.concatenate((training_outcome, np.zeros(dim)))\n",
    "    params = np.linalg.lstsq(mat, outcome, rcond=None)[0]\n",
    "    param_norm = np.linalg.norm(np.delete(params,dim-1)) \n",
    "    param_norms = np.append(param_norms, param_norm)\n",
    "\n",
    "\n",
    "    preds = []\n",
    "    for i in range(test_set.shape[0]):\n",
    "        pred = np.dot(test_set[i],params) \n",
    "        preds.append(pred)\n",
    "\n",
    "    dif = preds - test_outcome\n",
    "    norm_ = np.linalg.norm(dif)\n",
    "    fit_RMS.append(norm_/np.sqrt(dif.shape[0]))\n",
    "\n",
    "\n",
    "    \n",
    "lowest_RMS = np.argmin(fit_RMS)\n",
    "\n",
    "print(reg_param_values[lowest_RMS])\n",
    "print(fit_RMS[lowest_RMS])\n",
    "print(param_norms[lowest_RMS])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
